{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load LSTM network and generate text\n",
    "import sys\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  144052\n",
      "Total Vocab:  45\n"
     ]
    }
   ],
   "source": [
    "# load ascii text and covert to lowercase\n",
    "filename = \"Alice.txt\"\n",
    "raw_text = open(filename, encoding=\"utf8\").read()\n",
    "raw_text = raw_text.lower()\n",
    "# create mapping of unique chars to integers, and a reverse mapping\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "# summarize the loaded data\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print (\"Total Characters: \", n_chars)\n",
    "print (\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  143952\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "\tseq_in = raw_text[i:i + seq_length]\n",
    "\tseq_out = raw_text[i + seq_length]\n",
    "\tdataX.append([char_to_int[char] for char in seq_in])\n",
    "\tdataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print (\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)\n",
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" y to itself ‘then i’ll\n",
      "go round and get in at the window.’\n",
      "\n",
      "‘that you won’t’ thought alice, and, aft \"\n"
     ]
    }
   ],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-00-2.9960.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "#Pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print (\"Seed:\")\n",
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# generate characters\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print (\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4th Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" ow,’ thought alice, ‘to speak to this mouse?\n",
      "everything is so out-of-the-way down here, that i shoul \"\n"
     ]
    }
   ],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-03-2.5877.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "#Pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print (\"Seed:\")\n",
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " toe toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee to the toeee t\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# generate characters\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print (\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5th epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" ent down its head to hide a smile: some of the other birds\n",
      "tittered audibly.\n",
      "\n",
      "‘what i was going to s \"\n"
     ]
    }
   ],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-04-2.5181.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "#Pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print (\"Seed:\")\n",
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ee ’ou don toe toee ’hu ’ou don toe toee ’hu ’ou don toe toee ’h\n",
      "the toee t\n",
      "she sas io the toeee  ‘he wout to the toeee to the toeee to the toeee to the toeee  ‘he wout to the toeee to the toeee to the toeee to the toeee  ‘he wout to the toeee to the toeee to the toeee to the toeee  ‘he wout to the toeee to the toeee to the toeee to the toeee  ‘he wout to the toeee to the toeee to the toeee to the toeee  ‘he wout to the toeee to the toeee to the toeee to the toeee  ‘he wout to the toeee to the toeee to the toeee to the toeee  ‘he wout to the toeee to the toeee to the toeee to the toeee  ‘he wout to the toeee to the toeee to the toeee to the toeee  ‘he wout to the toeee to the toeee to the toeee to the toeee  ‘he wout to the toeee to the toeee to the toeee to the toeee  ‘he wout to the toeee to the toeee to the toeee to the toeee  ‘he wout to the toeee to the toeee to the toeee to the toeee  ‘he wout to the toeee to the toeee to the toeee to the toeee  ‘he wout to the toeee to the toeee\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# generate characters\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print (\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6th Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" , and shook itself. then it got down off the\n",
      "mushroom, and crawled away in the grass, merely remarki \"\n"
     ]
    }
   ],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-05-2.4579.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "#Pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print (\"Seed:\")\n",
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the was oo the toeee tar an  lhe was aol the wooee tar io the tooee an  lhe was aol the wooee tar io the tooee an  lhe was aol the wooee tar io the tooee an  lhe was aol the wooee tar io the tooee an  lhe was aol the wooee tar io the tooee an  lhe was aol the wooee tar io the tooee an  lhe was aol the wooee tar io the tooee an  lhe was aol the wooee tar io the tooee an  lhe was aol the wooee tar io the tooee an  lhe was aol the wooee tar io the tooee an  lhe was aol the wooee tar io the tooee an  lhe was aol the wooee tar io the tooee an  lhe was aol the wooee tar io the tooee an  lhe was aol the wooee tar io the tooee an  lhe was aol the wooee tar io the tooee an  lhe was aol the wooee tar io the tooee an  lhe was aol the wooee tar io the tooee an  lhe was aol the wooee tar io the tooee an  lhe was aol the wooee tar io the tooee an  lhe was aol the wooee tar io the tooee an  lhe was aol the wooee tar io the tooee an  lhe was aol the wooee tar io the tooee an  lhe was aol the wooee ta\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# generate characters\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print (\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10th Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" l like the tone of this remark, and thought it would\n",
      "be as well to introduce some other subject of c \"\n"
     ]
    }
   ],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-09-2.2508.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "#Pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print (\"Seed:\")\n",
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erre an the cade  ‘he woe tondd to tee oo the toiee of the sene th the toiee of the sene th the toiee of the soeee’s oaae to the care \n",
      "‘he iors t aaded the pant rf tieee an an cnd tf the care \n",
      "‘he ions ’ shi gact sard teed to herself, ‘ih wou den toe toie to tee  the care oo the woide oo the toiee of the sene th the toiee of the sare  ‘hh wou dan  i thnl toe toine to toe the whit ’ou dane ’hu ’hu  the wes a lond tane the woide an in sae it the was oo the toiee  the was anl the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the was ani the wa\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# generate characters\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print (\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15th Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" ould not help bursting out\n",
      "laughing: and when she had got its head down, and was going to begin\n",
      "agai \"\n"
     ]
    }
   ],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-14-2.0516.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "#Pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print (\"Seed:\")\n",
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n, and the paot on the was oo tire to tee ott of the tooe of the goor and the pabtir  and taid to herself, ‘ho whs ho would be anleer then io ’hu  toe tey an i crn’t wan i can’t sale the thieg taat i thil di iode to tee iore th the toiee  the medt ii the rabt of the rabt of the gous of the toid  the was toe tabe to the care oa thene to tee whot has sie tage th the goush  and the part on the kad boen hartel  the was toe tane the was anl the wast on the kad bade to the croroe of the garter, and the whrtght the was toe tane the gad deen woine the was toen i shnlld th the toiee  the was toe tane toine to the whrte tat and the war oo the was of the garter, and the whrtght th the sereo hare was soen i can to toe to the whote th the toiee  the fad not the rabt oo the rooe of the goor aadi  toe teeee the whst hnt lane to toenk the was toen i shnll  the dodr had f veal d cruaous was io to hen the while rabbit, and the was a lott eerting  toen a lotg oale to the was ani the was of the garter, an\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# generate characters\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print (\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20th Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" the hatter,\n",
      "who turned pale and fidgeted.\n",
      "\n",
      "‘give your evidence,’ said the king; ‘and don’t be nervou \"\n"
     ]
    }
   ],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-19-1.8998.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "#Pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print (\"Seed:\")\n",
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s in the reae th the soiet.’\n",
      "\n",
      "‘io tou dann to tey at the rame thing ’ said the macter.i\n",
      "think inr tonee \n",
      "‘oo sooh the whut mntele toune ’hu  i whnlk yhu would be aene the reae the soint!’\n",
      "and the rooe oo the coor aadk  woo the oatter whth the boor  and taed to alice aedin, and she thought the lad foond th the coor and boond th the tooe of the theee sabdit, and the whrt snen iid to the little door, and the whrt sald to the lintee the horst of the garter with the sooe of the toeee  she found the had not the door and boond th the tooe of the toeee saed \n",
      "‘hh you moot beoe th the that a tein of ier!’hu h wholg thet ’ould be aute of the toie,’\n",
      "\n",
      "‘h too’t an an all ’hu ao a lange time,’ she mock turtle waid, ‘in would be angee an in she that so thee!’ \n",
      "‘her tee aoongsed the gorst oatee the saak th the tait of thet iire ’huh the sore  a donst to taid the hoos and the rabbit sat aning thee, and the whrt snen wiue toeer beong th the thaters, and the tooe to the whrt on the kooke of the gorse tht \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# generate characters\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print (\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Larger Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)\n",
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" e going on between\n",
      "the executioner, the king, and the queen, who were all talking at once,\n",
      "while all \"\n"
     ]
    }
   ],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-00-2.8226-bigger.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "#Pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print (\"Seed:\")\n",
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot the moot \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# generate characters\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print (\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5th Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" le use without my shoulders. oh, how i wish i could\n",
      "shut up like a telescope! i think i could, if i  \"\n"
     ]
    }
   ],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-04-1.9510-bigger.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "#Pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print (\"Seed:\")\n",
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "was a little boeat her her that it would be a harder to the was a little bear to herself it to herself in a little oi the courd, and she was the was to herself to herself and the was a little oi the courd, and she was the was to herself to herself and the was a little oi the courd, and she was the was to herself to herself and the was a little oi the courd, and she was the was to herself to herself and the was a little oi the courd, and she was the was to herself to herself and the was a little oi the courd, and she was the was to herself to herself and the was a little oi the courd, and she was the was to herself to herself and the was a little oi the courd, and she was the was to herself to herself and the was a little oi the courd, and she was the was to herself to herself and the was a little oi the courd, and she was the was to herself to herself and the was a little oi the courd, and she was the was to herself to herself and the was a little oi the courd, and she was the was to h\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# generate characters\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print (\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10th Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\"  him--how was it, old fellow? what happened to you? tell\n",
      "us all about it!’\n",
      "\n",
      "last came a little feebl \"\n"
     ]
    }
   ],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-09-1.6653-bigger.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "#Pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print (\"Seed:\")\n",
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng of the court of the court of the court as the could not head to be no tie foure, and the was not a little bright of the court of the court of the court of the court of the court as the court was  the found nf the court was the dourt of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the court of the co\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# generate characters\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print (\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15th Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" l look!\n",
      "\n",
      "     alice’s right foot, esq.\n",
      "       hearthrug,\n",
      "         near the fender,\n",
      "           (with  \"\n"
     ]
    }
   ],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-14-1.5134-bigger.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "#Pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print (\"Seed:\")\n",
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                   ‘c tiil                                                                                                    ‘c tiil                                                                                                    ‘c tiil                                                                                                    ‘c tiil                                                                                                    ‘c tiil                                                                                                    ‘c tiil                                                                                                    ‘c tiil                                                                                                    ‘c tiil                                                                                                    ‘c tiil                                      \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# generate characters\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print (\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16th Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\"  alice! when she got to the\n",
      "door, she found she had forgotten the little golden key, and when she\n",
      "we \"\n"
     ]
    }
   ],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-15-1.4891-bigger.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "#Pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print (\"Seed:\")\n",
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nt on with the toods, and the white rabbit was a long table to she weite rooe time the was a long table as the could, and she went on as she was soo suite put of tight and said to the was oot of tight and said to the were seally to see the words as the court, and she went on with the toods, and the white rabbit was a long table to she weite rooe time the was a long table as the could, and she went on as she was soo suite put of tight and said to the was oot of tight and said to the were seally to see the words as the court, and she went on with the toods, and the white rabbit was a long table to she weite rooe time the was a long table as the could, and she went on as she was soo suite put of tight and said to the was oot of tight and said to the were seally to see the words as the court, and she went on with the toods, and the white rabbit was a long table to she weite rooe time the was a long table as the could, and she went on as she was soo suite put of tight and said to the was oo\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# generate characters\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print (\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20th Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" he now hastily\n",
      "began again, using the ink, that was trickling down his face, as long as\n",
      "it lasted.)\n",
      " \"\n"
     ]
    }
   ],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-19-1.4143-bigger.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "#Pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print (\"Seed:\")\n",
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‘when i could not think i sron ’ said the mock turtle.\n",
      "\n",
      "‘i don’t know what they would be of you all rhe same thing i shat loce,’ said the mock turtle.\n",
      "\n",
      "‘i don’t know what they would be of you all rhe same thing i shat loce,’ said the mock turtle.\n",
      "\n",
      "‘i don’t know what they would be of you all rhe same thing i shat loce,’ said the mock turtle.\n",
      "\n",
      "‘i don’t know what they would be of you all rhe same thing i shat loce,’ said the mock turtle.\n",
      "\n",
      "‘i don’t know what they would be of you all rhe same thing i shat loce,’ said the mock turtle.\n",
      "\n",
      "‘i don’t know what they would be of you all rhe same thing i shat loce,’ said the mock turtle.\n",
      "\n",
      "‘i don’t know what they would be of you all rhe same thing i shat loce,’ said the mock turtle.\n",
      "\n",
      "‘i don’t know what they would be of you all rhe same thing i shat loce,’ said the mock turtle.\n",
      "\n",
      "‘i don’t know what they would be of you all rhe same thing i shat loce,’ said the mock turtle.\n",
      "\n",
      "‘i don’t know what they would be of you all rhe same thing i shat loce,’ said th\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# generate characters\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print (\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 25th Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\"  side as\n",
      "she spoke.\n",
      "\n",
      "alice did not much like keeping so close to her: first, because the\n",
      "duchess was \"\n"
     ]
    }
   ],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-24-1.3495-bigger.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "#Pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print (\"Seed:\")\n",
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " seedried to for and the white rabbit, who had fone the white rabbit wand the white rabbit, who had fone the white rabbit went on again. \n",
      "‘i don’t know what it was the sooessesl of mearing on your hase’ in the same thing,’ said the caterpillar.\n",
      "\n",
      "‘i don’t know what it was the sooessesl of mearing on your hase’ in the same thing,’ she said to herself, ‘it was a little brss of the court, and the words had a large coor was a good oe the sable  whth a serpent to the way of the sable  which was sooe of the soof of the sorf of the coor with the way to speak and sound the coor with the sable  which was so speaked to food and horonw in the sable, and the was now mong the white rabbit wand the white rabbit went on again. \n",
      "‘i don’t know what it was the sooessesl of mearing on your hase’ in the same thing,’ said the caterpillar.\n",
      "\n",
      "‘i don’t know what it was the sooessesl of mearing on your hase’ in the same thing,’ she said to herself, ‘it was a little brss of the court, and the words had a large co\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# generate characters\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print (\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 30th Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\"  she gave her\n",
      "answer. ‘they’re done with blacking, i believe.’\n",
      "\n",
      "‘boots and shoes under the sea,’ the \"\n"
     ]
    }
   ],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-29-1.3060-bigger.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "#Pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print (\"Seed:\")\n",
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " mock turtle replied; ‘and well she mooked to the garden that it was a very curious to the white rabbits. i shall have a ceat of hard and the mock turtle in the season in the same tiing as all. and i could not the same thing as the rabbit was a grown of little things of her tie catt- and she was a little shree had a coof of the roof, and the white rabbit were goleed herself hartelf in a low voice, ‘i can’t have to be a very curious thing as the same thing as all.’\n",
      "\n",
      "‘i con’t know that the mors in the sea,’ the mock turtle replied. ‘and the mors of the season in the seas the sable it the same thing as the same thing as the same with the puher like and the topds, ‘i never heard the mock turtle to be a crown of this to the things a hind that i aan mevs!’ and the mock turtle seplingd her hand, and the was a little shree had a coof of the rabbit, and was see that the was a little shree had a coof of the roof, and the white rabbit were goleed herself hartelf in a low voice, ‘i can’t have to b\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# generate characters\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print (\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 35th Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\"  well enough, when i find a thing,’ said the\n",
      "duck: ‘it’s generally a frog or a worm. the question is \"\n"
     ]
    }
   ],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-34-1.2767-bigger.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "#Pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print (\"Seed:\")\n",
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " i can’t have to do and saying it in the soo of the sorp of the sort of a cat- and the mort of mneering them at the was a good of the room of the coorse of the mock turtle, and the whole party tas at the mooent that she was a long sider of the tort of little coor with the tort of the court, \n",
      "‘what a curious ferting,’ the mock turtle raid to herself, ‘the white of you to go to tell you the thme,’\n",
      "\n",
      "‘i don’t know it the mart was, that i can’t hete?’ said the king.\n",
      "\n",
      "alice was she first to speak again, to her feet, and he cameed a little shree harden, and the thoe the had not het the white rabbit was in the same tile the white rabbit, who was not a lintte or two so the white rabbit, who was not a linute or two to the thingl gatper in the soog, and the whnle party tas on its head to her head  and the puher was so much frrg of the thise gad bouid a little bod coorersation in the soo of the mock turtle, and the whole party tas at the mooent that she was a long sider of the tort of little coor \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# generate characters\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print (\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 40th Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" mping on the\n",
      "ground as she spoke; ‘either you or your head must be off, and that in\n",
      "about half no ti \"\n"
     ]
    }
   ],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-39-1.2573-bigger.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "#Pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print (\"Seed:\")\n",
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "me, the dourt ceenre the cooq was she same thing as she could gooe to the door, and the was suicking of the coor, so she went on was to any of the top of the torg of the topg, and the went on, ‘what a cucctter and things and more to be so uerter to the season in the book out of the sea--the was quite slates and forgot that they wanked off a thate of the garden, and she went on, ‘what a cucctter and things that they would be a very little bod oo the season in the sopp of the sopg of the mock turtle, and the mock turtle said to the coor with her sister, and the went on, ‘what a cucctter and things would be a loog slare of the bouter, i dan’t seml the bouter, and the mock turtle in the bir, and the mors of the season of that is--“bhio in the season in the sopp of things and then i can begn the same thing a busious of the bouter, i dan’t seml the bouter, and the mors course, and the mock turtle in the bir, and the mors courses of the coors of the garden, and she went on, ‘what a cucctter a\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# generate characters\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print (\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 45th Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" ‘you ought to be ashamed of yourself for asking such a simple question,’\n",
      "added the gryphon; and then \"\n"
     ]
    }
   ],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-44-1.2435-bigger.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "#Pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print (\"Seed:\")\n",
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the was a long sat off and findssed and frowd and growning to be a good that her upe than a louse- and she was a little bottle that she was a little bottle that she was a long sat off and findssed anxiously in the woods and foowent at the cook of the court, without anl her head to her feat off a little boti the way of the waseh out of the had been from the coor fegling her anm of the walted hip to be a good deal of the court, and she was a little sable sail, ‘i don’t be in biine of the sopg,’ the said to herself, ‘i don’t know what i can co she wayen cone with the soof.-and i wonder if you’d been to be a louse- i shall have to see the queen of heress then they could heve you foen the door was an ole surples it wo do would be a bonl with the soof.-and i could heve that the rueen taid an i to get in any more, and i dould heve the queen of here!’\n",
      "\n",
      "the kored of the rueen think the was a long sureersed ouire as she was now a thake to the door thar said to alice, and said to the gatter.\n",
      "\n",
      "‘i\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# generate characters\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print (\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50th Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" he hall;\n",
      "but, alas! either the locks were too large, or the key was too small,\n",
      "but at any rate it wo \"\n"
     ]
    }
   ],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-49-1.2355-bigger.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "#Pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print (\"Seed:\")\n",
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uld be afgan with the coorsat- and the could not hear her sook alice to bo thls sime of the sop of her so cane and lake out of the sor of her so ceange the cooroniu. \n",
      "alice could not sell the white rabbit was she fisst to see the queen of hearts was that it was and such a conwersation. \n",
      "alice was soo much siled ald she was not a terped out of the court, and the cormouse sat on it were like to be a very little coor up in a little botrle so the way to she way of a cat in the dirtance, and she was suilllng and foowing down to the dooroat with the coor and said this the waite of little thing had been brotnde and began to many wiilg and began and to do and heart and then the words what would be a very little qiseatiog a wery little cool whth the dooro of the coors- and the could not hear her head to her to the cooroat.\n",
      "\n",
      "‘what a pitylng of the sondier,’ said the mock turtle.\n",
      "\n",
      "‘what a mors and all marders that it would be a cit,’ said the cormouse, who was said to she way of saying to she doo\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# generate characters\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print (\"\\nDone.\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
